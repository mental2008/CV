%! TEX TS-program = xelatex
% --- LaTeX CV Template - Lingyun Yang ---

% Set document class and font size
\documentclass[letterpaper, 12pt]{article}
\usepackage[utf8]{inputenc}

% Package imports
\usepackage{setspace, longtable, graphicx, hyphenat, hyperref, fancyhdr, ifthen, everypage, enumitem, amsmath, setspace, xeCJK, ulem}

% --- Page layout settings --- %

% Set page margins
\usepackage[left=0.3in, right=0.3in, bottom=0.7in, top=0.7in]{geometry}

% Set font to Libertine, including math support
\usepackage{libertine}
\usepackage[libertine]{newtxmath}

% Set line spacing
\renewcommand{\baselinestretch}{1.15}

% --- Page formatting ---

% Set link colors
% \usepackage[dvipsnames]{xcolor}
% \hypersetup{colorlinks=true, linkcolor=RoyalBlue, urlcolor=RoyalBlue}

% Hind links
\hypersetup{hidelinks}

% Remove page numbering
% \pagenumbering{gobble}

% --- Document starts here ---

\begin{document}

% Name and date of last update to this document
\noindent{\huge{Lingyun Yang (杨凌云)}
\hfill{\it\footnotesize Updated \today}}

% --- Start the two-column table storing the main content ---

% Set spacing between columns
\setlength{\tabcolsep}{10pt}

% --- Contact information and other items --- %

\vspace{0.5cm}
\begin{center}
\begin{tabular}{lll}
% % Line 1: Email, GitHub, LinkedIn
\textbf{Email}: \href{mailto:lyangbk@cse.ust.hk}{\underline{lyangbk@cse.ust.hk}} &
\hspace{0.25in} \textbf{GitHub}: \href{https://github.com/mental2008}{\underline{mental2008}} &
\hspace{0.25in} \textbf{LinkedIn}: \href{https://www.linkedin.com/in/stephenyang1999/}{\underline{stephenyang1999}} \\

% % Line 2: Phone number, office location, website
\textbf{Phone}: (+86) 135-0284-6103 &
\hspace{0.25in} \textbf{Office}: BDI 101, UC, HKUST &
\hspace{0.25in} \textbf{Web}: \href{https://www.lingyunyang.com/}{\underline{https://www.lingyunyang.com/}} \\
\end{tabular}
\end{center}

% Set the width of each column
% \begin{longtable}{p{1.3in}p{4.8in}}
% \begin{longtable}{p{1.3in}p{5.0in}}
\begin{longtable}{p{1.0in}p{5.8in}}

% --- Section: Personal profile --- %
% {\textsc{Profile}}
% & Ph.D. Candidate \\
% & Department of Computer Science and Engineering \\
% & Hong Kong University of Science and Technology \\
% & Clear Water Bay, Kowloon, Hong Kong \\
% & \\

% --- Section: Research interests --- %
\nohyphens{\textsc{Research Interests}}
& I have a broad interest in resource management for large-scale data centers.
Specifically, my research focuses on: (a) improving \textit{resource efficiency} for AI/GPU clusters; (b) building \textit{efficient} and \textit{low-cost} AI model serving systems.
My first-authored papers have been published in top-tier systems conferences (NSDI, ATC, SoCC).
\\
& \\

{\textsc{Professional}}
& {\textbf{Alibaba Group}} \hfill Hangzhou, China \\
{\textsc{Experience}}
& \textit{Alibaba Holding--Aicheng Technology--Tech Infra and Reliablity Engineering (TRE)} \\
& Senior Engineer (P7) \hfill TBA \\
& $\diamond$ Director: Dr. Yinghao Yu \\
& \\

% --- Section: Education --- %
{\textsc{Education}}
& \textbf{Hong Kong University of Science and Technology (HKUST)} \\
& \textit{Department of Computer Science and Engineering} \\
& Ph.D. in Computer Science and Engineering \hfill Sep. 2020 -- Present \\
& $\diamond$ Advisor: Prof. Wei Wang \hfill (\textit{expected to graduate in Fall 2025}) \\
& \\

& \textbf{South China University of Technology (SCUT)} \\
& \textit{School of Computer Science and Engineering} \\
& B.Eng. in Computer Science and Technology \hfill Sep. 2016 -- Jul. 2020 \\
& $\diamond$ Studied at All-English Innovation Class (GPA: 3.82/4); National Scholarship. \\
& \\

% --- Section: Publications --- %
\nohyphens{\textsc{Publications}}
% & \textit{* denotes co-first authors, sort in alphabetical order} \\
& \textit{* denotes co-first authors} \\

& \textbf{Refereed Papers in Conference Proceedings} \\
\hfill [C5]
& Suyi Li*, \textbf{\emph{Lingyun Yang}}*, Xiaoxiao Jiang, Hanfeng Lu, Dakai An, Zhipeng Di, Weiyi Lu, Jiawei Chen, Kan Liu, Yinghao Yu, Tao Lan, Guodong Yang, Lin Qu, Liping Zhang, Wei Wang, “Katz: Efficient Workflow Serving for Diffusion Models with Many Adapters,” in the \textit{Proceedings of USENIX Annual Technical Conference} (\textbf{ATC '25}), Boston, MA, USA, July 2025. \textit{(\textbf{CCF-A}, acceptance rate: 100/634=15.8\%)} \\
\hfill [C4]
& \textbf{\emph{Lingyun Yang}}, Yongchen Wang, Yinghao Yu, Qizhen Weng, Jianbo Dong, Kan Liu, Chi Zhang, Yanyi Zi, Hao Li, Zechao Zhang, Nan Wang, Yu Dong, Menglei Zheng, Lanlan Xi, Xiaowei Lu, Liang Ye, Guodong Yang, Binzhang Fu, Tao Lan, Liping Zhang, Lin Qu, Wei Wang, “GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scale,” in the \textit{Proceedings of the 22nd USENIX Symposium on Networked Systems Design and Implementation} (\textbf{NSDI '25}), Philadelphia, PA, USA, April 2025. \textit{(\textbf{CCF-A}, acceptance rate: 55/401=13.7\%)} \\
\hfill [C3]
& Qizhen Weng*, \textbf{\emph{Lingyun Yang}}*, Yinghao Yu, Wei Wang, Xiaochuan Tang, Guodong Yang, Liping Zhang, “Beware of Fragmentation: Scheduling GPU-Sharing Workloads with Fragmentation Gradient Descent,” in the \textit{Proceedings of USENIX Annual Technical Conference} (\textbf{ATC '23}), Boston, MA, USA, July 2023. \textit{(\textbf{CCF-A}, acceptance rate: 65/353=18.4\%)} \\
\hfill [C2]
& Yongkang Zhang, Yinghao Yu, Wei Wang, Qiukai Chen, Jie Wu, Zuowei Zhang, Jiang Zhong, Tianchen Ding, Qizhen Weng, \textbf{\emph{Lingyun Yang}}, Cheng Wang, Jian He, Guodong Yang, and Liping Zhang, “Workload Management in Alibaba Clusters: The Good, the Bad, and the Ugly,” in the \textit{Proceedings of ACM Symposium on Cloud Computing} (\textbf{SoCC '22}), San Francisco, CA, USA, November 2022. \textit{(\textbf{CCF-B}, acceptance rate: 38/155=24.5\%)} \\
\hfill [C1]
& Luping Wang*, \textbf{\emph{Lingyun Yang}}*, Yinghao Yu, Wei Wang, Bo Li, Xianchao Sun, Jian He, and Liping Zhang, “Morphling: Fast, Near-Optimal Auto-Configuration for Cloud-Native Model Serving,” in the \textit{Proceedings of ACM Symposium on Cloud Computing} (\textbf{SoCC '21}), Seattle, WA, USA, November 2021. \textit{(\textbf{CCF-B}, acceptance rate: 46/145=31.7\%)} \\

& \textbf{In submission / Preprint} \\
\hfill [I1]
& Xiaoxiao Jiang*, Suyi Li*, Lingyun Yang, Tianyu Feng, Zhipeng Di, Weiyi Lu, Guoxuan Zhu, Xiu Lin, Kan Liu, Yinghao Yu, Tao Lan, Guodong Yang, Lin Qu, Liping Zhang, Wei Wang, “InstGenIE: Generative Image Editing Made Efficient with Mask-aware Caching and Scheduling,” \textit{arXiv:2505.20600}, 2025. \\

& \\

% --- Section: Professional experience ---

\nohyphens{\textsc{Internship}}
& \textbf{Alibaba Group \& Alibaba Cloud} \hfill Hangzhou, China \\
% & \textit{Technology Risk and Efficiency (TRE) -- Cluster Management -- AI Infrastructure} \\
& Research Intern \hfill Dec. 2020 -- Present \\
& $\diamond$ Mentor: Dr. Yinghao Yu \\

2024 -- 2025
& \textbf{\emph{Efficient Text-to-Image Diffusion Model Serving with Add-on Modules}} \\
    & $\diamond$ Developed Katz, a system that efficiently generates high-quality images with stable diffusion models and many adapters (i.e., ControlNets and LoRAs). \\
    & $\diamond$ Analyzed usage patterns of various adapters (ControlNets, LoRAs) based on \textbf{500k} request traces from production text-to-image services. \\
    & $\diamond$ Incorporated several novel system designs, such as ControlNet-as-a-Service, bounded asynchronous LoRA loading, latent parallelism for CFG computation. \\
    & $\diamond$ Achieved up to \textbf{7.8$\times$} in serving latency and \textbf{1.6$\times$} in throughput. \\
    & $\diamond$ One paper was accepted by \textbf{\emph{ATC '25}}. \\

2022 -- 2024
& \textbf{\emph{GPU-Disaggregated Serving for Deep Learning Recommendation Models}} \\
    & $\diamond$ Proposed a GPU-disaggregated DLRM serving system to eliminate \textit{resource mismatch} and meet \textit{elastic} demand; leveraged RDMA network to offload computation on separate GPU and CPU nodes; resource-aware graph partitioning; topology-aware scheduling. \\
    & $\diamond$ In daily scenarios (e.g., a crowded GPU cluster with > 90\% allocation rate), reduced CPU fragments by \textbf{53\%} and GPU fragments by \textbf{27\%}. In the Double 11 Shopping Festival, saved up to \textbf{90\%} of GPUs when loaning GPU servers from training clusters. \\
    & $\diamond$ One paper was accepted by \textbf{\emph{NSDI '25}}. \\

2021 -- 2023
& \textbf{\emph{Resource Fragmentation Analysis and Optimization for GPU-Sharing Clusters}} \\
    & $\diamond$ Formally quantified \textit{statistical GPU resource fragments} and proposed the \textit{fragmentation gradient descent} scheduling algorithm to reduce resource fragmentation. Our scheduling policy can significantly reduce \textit{unallocated} GPUs by up to \textbf{49\%} compared to state-of-the-art policies. [\href{https://github.com/hkust-adsl/kubernetes-scheduler-simulator}{\underline{code}}] [\href{https://github.com/alibaba/clusterdata/tree/master/cluster-trace-gpu-v2023}{\underline{trace}}] \\
    & $\diamond$ Developed ParaSet, a \textit{best-effort} workload on Kubernetes that dynamically adjusts the number of instances and resource requirements based on the real-time resource availability in the cluster. It aims to fill resource fragments in the cluster and is integrated into KubeDL for internal use. \\
    & $\diamond$ One paper was accepted by \textbf{\emph{ATC '23}}. \\

2021 -- 2022
& \textbf{\emph{Large-Scale GPU Sharing and Overcommitment in Production}} \\
    & $\diamond$ Enabled \textit{large-scale GPU sharing and overcommitment} in production clusters, with \textit{tens of thousands }of \textit{shared} GPU containers running daily. Support the co-location of GPU tasks with different priorities (e.g., \textit{latency-sensitive}, \textit{spot}, \textit{best-effort}). \\
    & $\diamond$ Specifically, I designed and implemented the \textit{node-level} agent and the \textit{cluster-level} controller. The agent periodically collects and reports resource usage metrics and \textit{dynamically} allocates GPU resources to containers. The controller calculates potential resource overcommitment and provides scheduling guidance to the cluster scheduler. \\

2020 -- 2021
& \textbf{\emph{Fast, Near-Optimal Auto-Configuration for Cloud-Native Model Serving}} \\
    & $\diamond$ Developed Morphling, an auto-configuration framework for AI serving on Kubernetes; combined \textit{meta-learning} and \textit{bayesian optimization} to quickly find the \textit{optimal} resource configuration (e.g., CPU cores, GPU timeshare, GPU memory, GPU type) and runtime parameters (e.g., batch size). [\href{https://github.com/kubedl-io/morphling}{\underline{code}}] \\
    & $\diamond$ It was widely used in Alibaba for automated recommendation of container resource specifications; part of Alibaba's open-sourced \href{https://github.com/kubedl-io/kubedl}{\underline{KubeDL}}, a \href{https://landscape.cncf.io/?item=provisioning--automation-configuration--kubedl}{\underline{CNCF sandbox}} project. \\
    & $\diamond$ One paper was accepted by \textbf{\emph{SoCC '21}}. \\

\\

& {\textbf{Microsoft Research Asia (MSRA)}} \hfill Beijing, China\\
& Research Intern, \textit{Innovation Engineering Group (IEG)} \hfill Jul. 2019 -- Jun. 2020 \\
    & $\diamond$ Mentors: Lewei Lu \& Chong Li \\
    & $\diamond$ Designed a novel pooling layer to enhance the robustness of image recognition models; built Neural Architecture Search (NAS) workflow for face recognition tasks; implemented various attention modules for face recognition models on CNTK. \\
    & $\diamond$ Star of Tomorrow Internship Award of Excellence. \\

& \\


% --- Section: Awards, scholarships, etc. --- %
% --- Note: section title is spread over two lines --- %
\nohyphens{\textsc{Awards}}
% {\textsc{Honors and }}
& $\diamond$ USENIX NSDI 2025 Student Grant \hfill Mar. 2025 \\

& $\diamond$ Postgraduate Scholarship \hfill 2020 -- 2024, HKUST \\
% {\textsc{Scholarships}}
& $\diamond$ Star of Tomorrow Internship Award of Excellence \hfill Jul. 2020, MSRA \\

& $\diamond$ Merit Student \& Excellent Student Cadre \hfill Nov. 2019, SCUT \\
& $\diamond$ National Scholarship \hfill Oct. 2019, China \\

& $\diamond$ Silver Medal, ICPC China Xi'an National Invitational Contest \hfill May 2019 \\
% & $\diamond$ Silver Medal, ICPC China Xian National Invitational \hfill May 2019 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ First Prize, 17th Guangdong Collegiate Programming Contest \hfill May 2019 \\

& $\diamond$ Silver Medal, 37Games Cup Programming Contest \hfill Apr. 2019 \\
% & $\diamond$ Silver Medal, 2019 Sanqi Mutual Entertainment Cup \hfill Apr. 2019 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ Gold Medal, SCUT ACM Programming Contest \hfill Apr. 2019 \\
% & $\diamond$ Gold Medal, 2019 South China University of Technology ACM \hfill Apr. 2019 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ Bronze Medal, ACM-ICPC Asia Xuzhou Regional Contest \hfill Oct. 2018 \\

& $\diamond$ Silver Medal, 1st Xiao Mi Collegiate Programming Contest \hfill Sep. 2018 \\

& $\diamond$ Gold Medal, SCUT ACM Programming Contest \hfill Apr. 2018 \\
% & $\diamond$ Gold Medal, 2018 South China University of Technology ACM \hfill Apr. 2018 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ The First Prize Scholarship \hfill Nov. 2017, SCUT \\

& $\diamond$ Bronze Medal, ACM-ICPC Asia Xian Regional Contest \hfill Oct. 2017 \\

& $\diamond$ Gold Medal, 12th China Youth Robot Competition \hfill Jul. 2012 \\

& $\diamond$ Champion, RoboCup Youth Robot World Cup, China Division \hfill Mar. 2012 \\
% & $\ \ $ Division Selection Competition \\
% & $\diamond$ Champion, 2012 RoboCup Youth Robot World Cup China \hfill Mar. 2012 \\
% & $\ \ $ Division Selection Competition \\

& \\

% --- Section: Academic services --- %
{\textsc{Academic}}
& \textbf{Artifact Evaluation Committee} \\
{\textsc{Services}}
& $\diamond$ ACM SIGCOMM (2024), IEEE HPCA (2024) \\
& $\diamond$ ACM SOSP (2023), USENIX OSDI (2023), USENIX ATC (2023), MLSys (2023) \\
& \textbf{External Conference Reviewer} \\
& $\diamond$ IEEE INFOCOM (2022--2025), IEEE ICDCS (2023, 2025) \\
& $\diamond$ ACM APSys (2021), IEEE MSN (2021), EAI Qshine (2020) \\
& \textbf{External Journal Reviewer} \\
& $\diamond$ IEEE Transactions on Cloud Computing (2025) \\
& \textbf{Student Volunteer} \\
& $\diamond$ ACM APNet (2023), IEEE ICMLC \& ICWAPR (2018) \\
& \\

% --- Section: Teaching activities --- %
{\textsc{Teaching}}
& \textbf{Hong Kong University of Science and Technology} \\
{\textsc{Activities}}
& \textit{Teaching Assistant, Department of Computer Science and Engineering} \\
& $\diamond$ CSIT6000O: Advanced Cloud Computing (Spring 2022, Spring 2023) \\
& $\diamond$ COMP4651: Cloud Computing and Big Data Systems (Spring/Fall 2021, Spring 2024) \\
& $\diamond$ COMP3511: Operating Systems (Fall 2023) \\
& \\

% --- Section: Other experience --- %
{\textsc{Undergraduate}}
& \textbf{ACM-ICPC Competition Group} \hfill SCUT \\
{\textsc{Experience}}
& \textit{Group Member \& Team Leader} \hfill 2016 -- 2019 \\
& $\diamond$ Coach: Prof. Chuhua Xian \\
& $\diamond$ Major domains: Dynamic Programming, Number Theory, Data Structure, etc. \\

& \textbf{Machine Learning \& Cybernetics Research Group} \hfill SCUT \\
& \textit{Undergraduate Research Assistant} \hfill 2017 -- 2019 \\
& $\diamond$ Advisor: Prof. Patrick Chan \\
& $\diamond$ Projects: Fundus Stitching, Tableware Recognition, Neural Network Visualization. \\

& \textbf{Tencent Innovation Club} \hfill SCUT, CSE \\
& \textit{Vice Chairman} \hfill 2018 -- 2019 \\
& $\diamond$ Led the \textit{largest} student club in SCUT CSE, sponsored by Tencent. \\

& \textbf{ByteDance Summer Camp} \hfill Beijing, China \\
& \textit{Camper}, Algorithm track \hfill Aug. 2019 \\
& $\diamond$ Mentor: Dr. Yibo Zhu \\
& $\diamond$ Totally 150 participants selected from more than 6k candidates (< 2.5\%). \\
% & $\diamond$ Trained a large scale BERT Model by using Pipeline and Model Parallelism. \\

% International Conference on Machine Learning and Cybernetics, International Conference on Wavelet Analysis and Pattern Recognition
% & \textbf{ICMLC \& ICWAPR} \hfill Chengdu, China \\
% & \textit{Student helper} \hfill Jul. 2018 \\

& \\

% --- Section: Various skills (programming, software, languages, etc.) ---
\nohyphens{\textsc{Skills}}
& Programming Languages: Golang, C++, Python, Javascript \\
& Toolkits: Kubernetes, Docker, Grafana, Git, \LaTeX, SQL, MarkDown \\
& Languages: English (fluent), Mandarin (Native speaker), Cantonese (Intermediate) \\
& \\

% --- Section: Other interests/hobbies ---

\nohyphens{\textsc{Miscellaneous}}
\nohyphens{\textsc{Misc}}
& Play basketball \& badminton \& squash, workout at the gym, foodie. \\
& My paper reading notes are available at \href{https://paper.lingyunyang.com/}{https://paper.lingyunyang.com/}. \\
% & In my spare time, I also write some blogs about interesting stuffs aperiodically. Here is my personal blog (in Chinese): \href{https://blog.yanglingyun.me/}{https://blog.yanglingyun.me/}. \\

% --- End of CV! --- %

\end{longtable}
\end{document}
