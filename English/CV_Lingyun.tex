%! TEX TS-program = xelatex
% --- LaTeX CV Template - Lingyun Yang ---

% Set document class and font size
\documentclass[letterpaper, 12pt]{article}
\usepackage[utf8]{inputenc}

% Package imports
\usepackage{setspace, longtable, graphicx, hyphenat, hyperref, fancyhdr, ifthen, everypage, enumitem, amsmath, setspace, xeCJK, ulem}

% --- Page layout settings --- %

% Set page margins
\usepackage[left=0.3in, right=0.3in, bottom=0.7in, top=0.7in]{geometry}

% Set font to Libertine, including math support
\usepackage{libertine}
\usepackage[libertine]{newtxmath}

% Set line spacing
\renewcommand{\baselinestretch}{1.15}

% --- Page formatting ---

% Set link colors
% \usepackage[dvipsnames]{xcolor}
% \hypersetup{colorlinks=true, linkcolor=RoyalBlue, urlcolor=RoyalBlue}

% Hind links
\hypersetup{hidelinks}

% Remove page numbering
% \pagenumbering{gobble}

% --- Document starts here ---

\begin{document}

% Name and date of last update to this document
\noindent{\huge{Lingyun Yang (杨凌云)}
\hfill{\it\footnotesize Updated \today}}

% --- Start the two-column table storing the main content ---

% Set spacing between columns
\setlength{\tabcolsep}{10pt}

% --- Contact information and other items --- %

\vspace{0.5cm}
\begin{center}
\begin{tabular}{lll}
% % Line 1: Email, GitHub, LinkedIn
\textbf{Email}: \href{mailto:lyangbk@cse.ust.hk}{\underline{lyangbk@cse.ust.hk}} &
\hspace{0.65in} \textbf{GitHub}: \href{https://github.com/mental2008}{\underline{mental2008}} &
\hspace{0.25in} \textbf{LinkedIn}: \href{https://www.linkedin.com/in/stephenyang1999/}{\underline{stephenyang1999}} \\

% % Line 2: Phone number, office location, website
\textbf{Phone}: (+86) 135-0284-6103 &
\hspace{0.65in} \textbf{Office}: BDI 101, UC, HKUST &
\hspace{0.25in} \textbf{Web}: \href{https://www.lingyunyang.com/}{\underline{https://www.lingyunyang.com/}} \\
\end{tabular}
\end{center}

% Set the width of each column
% \begin{longtable}{p{1.3in}p{4.8in}}
% \begin{longtable}{p{1.3in}p{5.0in}}
\begin{longtable}{p{0.7in}p{6.0in}}

% --- Section: Personal profile --- %
% {\textsc{Profile}}
% & Ph.D. Candidate \\
% & Department of Computer Science and Engineering \\
% & Hong Kong University of Science and Technology \\
% & Clear Water Bay, Kowloon, Hong Kong \\
% & \\

% --- Section: Research interests --- %
\nohyphens{\textsc{Research Interests}}
% \textsc{Research}
& I have a broad interest in resource management for large-scale data centers / AI infrastructure.
Specifically, my research focuses on: (a) improving \textit{resource efficiency} for AI/GPU clusters; (b) building \textit{efficient} and \textit{low-cost} AI model serving systems. \\
% \textsc{Interests}
& \\

% --- Section: Education --- %
{\textsc{Education}}
& \textbf{Hong Kong University of Science and Technology (HKUST)} \\
& \textit{Department of Computer Science and Engineering} \\
& Ph.D. in Computer Science and Engineering \hfill Sep. 2020 -- Present \\
& $\diamond$ Advisor: Prof. Wei Wang \hfill (\textit{expected to graduate in Fall 2025}) \\
& \\

& \textbf{South China University of Technology (SCUT)} \\
& \textit{School of Computer Science and Engineering} \\
& B.Eng. in Computer Science and Technology \hfill Sep. 2016 -- Jul. 2020 \\
& $\diamond$ Studied at All-English Innovation Class (GPA: 3.82/4); National Scholarship. \\
& \\

% --- Section: Professional experience ---

\nohyphens{\textsc{Internship}}
% {\textsc{Professional}}
& {\textbf{Alibaba Group \& Alibaba Cloud}} \hfill Hangzhou, China \\
% {\textsc{Experience}}
& \textit{Research Intern}, Cluster Management Group, AI Infra \hfill Dec. 2020 -- Present \\
& $\diamond$ Mentor: Dr. Yinghao Yu \\

% & \textbf{Resource Management for AI/GPU Clusters} \\

% & \textit{\emph{Mitigate GPU Resource Fragmentation}} \\
    & $\diamond$
    Defragment GPUs in Heterogeneous GPU Clusters (\underline{ATC 2023}).
    % [\textbf{ATC 2023, C3}]
    % Formally quantified \textit{statistical GPU resource fragments} and proposed the \textit{fragmentation gradient descent} scheduling algorithm to reduce resource fragmentation. Our scheduling policy can significantly reduce \textit{unallocated} GPUs by up to 49\% compared to state-of-the-art policies.
    % [\href{https://github.com/hkust-adsl/kubernetes-scheduler-simulator}{\underline{code}}]
    % [\href{https://github.com/alibaba/clusterdata/tree/master/cluster-trace-gpu-v2023}{\underline{trace}}]
    \\

    % & $\diamond$
    % [\textbf{Under Review, I1}]
    % Proposed a GPU-disaggregated DLRM serving system to eliminate \textit{resource mismatch} and meet \textit{elastic} demand.
    % By leveraging RDMA network to \textit{separately} compute the computation graph on GPU and CPU nodes, it reduced CPU fragments by 53\% and GPU fragments by 27\%.
    % During seasonal traffic peaks (e.g., Double 11 Shopping Festival), it saved up to 90\% of GPUs when loaning GPU servers from training clusters. \\
    \\

    % & $\diamond$ Developed ParaSet, a \textit{best-effort} workload on Kubernetes that dynamically adjusts the number of instances and resource requirements based on the real-time resource availability in the cluster. It aims to fill resource fragments in the cluster and is integrated into KubeDL for internal use. \\

% & \textit{\emph{Large-Scale GPU Sharing in Production}} \\
%     & $\diamond$ Enabled \textit{large-scale GPU sharing} in production clusters, with over 10k shared GPU containers running daily. Support the co-location of GPU tasks with different priorities (e.g., \textit{latency-sensitive}, \textit{best-effort}). Designed and implemented the \textit{node-level} agent and the \textit{cluster-level} controller. The agent periodically collects and reports resource usage metrics and dynamically allocates GPU resources to containers. The controller calculates potential resource overcommitment and provides scheduling guidance to the cluster scheduler. \\

% & \textbf{Efficient and Low-cost AI Model Serving Systems} \\
% & \textit{\emph{Efficient Text-to-Image Diffusion Model Serving with Add-on Modules}} \\
%     & $\diamond$
%         [\textbf{Under Review, I2}]
%         Developed SwiftDiffusion, a system that efficiently generates high-quality images with stable diffusion models and add-on modules (i.e., ControlNets and LoRAs). Incorporated serveral novel designs, including ControlNet-as-a-Service, asynchronous LoRA loading, and kernel optimization. Achieved up to 7.8$\times$ in latency and 1.6$\times$ in throughput without compromising image quality.\\
% & \textit{\emph{Auto-Configuration for AI Serving Service}} \\
%     & $\diamond$
%     [\textbf{SoCC 2021, C1}]
%     Developed Morphling, an open-source auto-configuration framework for AI serving on Kubernetes.
%     Combined \textit{meta-learning} and \textit{bayesian optimization} to quickly find the \textit{optimal} resource configuration (e.g., CPU cores, GPU timeshare, GPU memory, GPU type) and runtime parameters (e.g., batch size).
%     % It was widely used in Alibaba for automated recommendation of container resource specifications.
%     [\href{https://github.com/kubedl-io/morphling}{\underline{code}}]
%     \\
% & \\

& {\textbf{Microsoft Research Asia (MSRA)}} \hfill Beijing, China\\
& \textit{Research Intern}, Innovation Engineering Group (IEG) \hfill Jul. 2019 -- Jun. 2020 \\
    % & $\diamond$ Mentors: Lewei Lu \& Chong Li \\
    % & $\diamond$ Designed a symmetric padding pooling layer with self-attention which can be easily integrated into any model structure, achieve the state-of-the-art performance and improve the robustness to various pertubations. \\
    % & $\diamond$ Built a neural architecture search pipeline for face recognition tasks. \\
    % & $\diamond$ Applied multiple latest attention mechanisms to face recognition models, integrated with knowledge distillation, built in CNTK. \\
    & $\diamond$ Conducted research on model robustness, face recognition, attention mechanisms, knowledge distillation, and neural architecture search; Star of Tomorrow Internship Award of Excellence. \\

% & $\diamond$ Applied multiple latest attention mechanisms to face recognition models, integrated with knowledge distillation, built in CNTK. \\
% & $\diamond$ Built a neural architecture search pipeline for face recognition tasks. \\
% & $\diamond$ Designed a symmetric padding pooling layer with self-attention which can be easily integrated into any model structure, achieve the state-of-the-art performance and improve the robustness to various pertubations. \\
& \\

% --- Section: Publications --- %
\nohyphens{\textsc{Publications}}
& \textit{* denotes co-first authors, sort in alphabetical order} \\
& \textbf{Refereed Papers in Conference Proceedings} \\
\hfill [C3]
& Qizhen Weng*, \textbf{\emph{Lingyun Yang}}*, Yinghao Yu, Wei Wang, Xiaochuan Tang, Guodong Yang, Liping Zhang, “Beware of Fragmentation: Scheduling GPU-Sharing Workloads with Fragmentation Gradient Descent,” in the \textit{Proceedings of USENIX Annual Technical Conference} (\textbf{ATC '23}), Boston, MA, USA, July 2023. \textit{(\textbf{CCF-A}, acceptance rate: 65/353=18.4\%)} \\
\hfill [C2]
& Yongkang Zhang, Yinghao Yu, Wei Wang, Qiukai Chen, Jie Wu, Zuowei Zhang, Jiang Zhong, Tianchen Ding, Qizhen Weng, \textbf{\emph{Lingyun Yang}}, Cheng Wang, Jian He, Guodong Yang, and Liping Zhang, “Workload Management in Alibaba Clusters: The Good, the Bad, and the Ugly,” in the \textit{Proceedings of ACM Symposium on Cloud Computing} (\textbf{SoCC '22}), San Francisco, CA, USA, November 2022. \textit{(\textbf{CCF-B}, acceptance rate: 38/155=24.5\%)} \\
\hfill [C1]
& Luping Wang*, \textbf{\emph{Lingyun Yang}}*, Yinghao Yu, Wei Wang, Bo Li, Xianchao Sun, Jian He, and Liping Zhang, “Morphling: Fast, Near-Optimal Auto-Configuration for Cloud-Native Model Serving,” in the \textit{Proceedings of ACM Symposium on Cloud Computing} (\textbf{SoCC '21}), Seattle, WA, USA, November 2021. \textit{(\textbf{CCF-B}, acceptance rate: 46/145=31.7\%)} \\
& \textit{In submission / Preprint} \\
\hfill [I2]
& Suyi Li*, \textbf{\emph{Lingyun Yang}}*, Xiaoxiao Jiang, Hanfeng Lu, Zhipeng Di, Weiyi Lu, Jiawei Chen, Kan Liu, Yinghao Yu, Tao Lan, Guodong Yang, Lin Qu, Liping Zhang, Wei Wang, “SwiftDiffusion: Efficient Diffusion Model Serving with Add-on Modules,” \textit{arXiv preprint arXiv:2407.02031}, 2024. \\
\hfill [I1]
& \textbf{\emph{Lingyun Yang}}, Yongchen Wang, Yinghao Yu, Qizhen Weng, Jianbo Dong, Kan Liu, Chi Zhang, Yanyi Zi, Hao Li, Zechao Zhang, Nan Wang, Yu Dong, Menglei Zheng, Lanlan Xi, Xiaowei Lu, Liang Ye, Guodong Yang, Binzhang Fu, Tao Lan, Liping Zhang, Lin Qu, Wei Wang, “GPU-Disaggregated Serving for Deep Learning Recommendation Models at Scale,” \textit{under review}. \\
& \\

% --- Section: Awards, scholarships, etc. --- %
% --- Note: section title is spread over two lines --- %
\nohyphens{\textsc{Awards}}
% {\textsc{Honors and }}
& $\diamond$ Postgraduate Scholarship \hfill 2020 -- 2024, HKUST \\
% {\textsc{Scholarships}}
& $\diamond$ Star of Tomorrow Internship Award of Excellence \hfill Jul. 2020, MSRA \\

& $\diamond$ Merit Student \& Excellent Student Cadre \hfill Nov. 2019, SCUT \\
& $\diamond$ National Scholarship \hfill Oct. 2019, China \\

& $\diamond$ Silver Medal, ICPC China Xi'an National Invitational Contest \hfill May 2019 \\
% & $\diamond$ Silver Medal, ICPC China Xian National Invitational \hfill May 2019 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ First Prize, 17th Guangdong Collegiate Programming Contest \hfill May 2019 \\

& $\diamond$ Silver Medal, 37Games Cup Programming Contest \hfill Apr. 2019 \\
% & $\diamond$ Silver Medal, 2019 Sanqi Mutual Entertainment Cup \hfill Apr. 2019 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ Gold Medal, SCUT ACM Programming Contest \hfill Apr. 2019 \\
% & $\diamond$ Gold Medal, 2019 South China University of Technology ACM \hfill Apr. 2019 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ Bronze Medal, ACM-ICPC Asia Xuzhou Regional Contest \hfill Oct. 2018 \\

& $\diamond$ Silver Medal, 1st Xiao Mi Collegiate Programming Contest \hfill Sept. 2018 \\

& $\diamond$ Gold Medal, SCUT ACM Programming Contest \hfill Apr. 2018 \\
% & $\diamond$ Gold Medal, 2018 South China University of Technology ACM \hfill Apr. 2018 \\
% & $\ \ $ Programming Contest \\

& $\diamond$ The First Prize Scholarship \hfill Nov. 2017, SCUT \\

& $\diamond$ Bronze Medal, ACM-ICPC Asia Xian Regional Contest \hfill Oct. 2017 \\

& $\diamond$ Gold Medal, 12th China Youth Robot Competition \hfill Jul. 2012 \\

& $\diamond$ Champion, RoboCup Youth Robot World Cup, China Division \hfill Mar. 2012 \\
% & $\ \ $ Division Selection Competition \\
% & $\diamond$ Champion, 2012 RoboCup Youth Robot World Cup China \hfill Mar. 2012 \\
% & $\ \ $ Division Selection Competition \\

& \\

% --- Section: Academic services --- %
{\textsc{Academic}}
& \textbf{Artifact Evaluation Committee} \\
{\textsc{Services}}
& $\diamond$ SIGCOMM (2024), HPCA (2024), SOSP (2023), OSDI (2023), ATC (2023), MLSys (2023) \\
& \textbf{External Reviewer} \\
& $\diamond$ INFOCOM (2022--2025), ICDCS (2023), APSys (2021), MSN (2021), Qshine (2020) \\
& \textbf{Student Volunteer} \\
& $\diamond$ APNet (2023), ICMLC \& ICWAPR (2018) \\
& \\

% --- Section: Teaching activities --- %
{\textsc{Teaching}}
& \textbf{Hong Kong University of Science and Technology} \\
{\textsc{Activities}}
& \textit{Teaching Assistant, Department of Computer Science and Engineering} \\
& $\diamond$ CSIT6000O: Advanced Cloud Computing (Spring 2022, Spring 2023) \\
& $\diamond$ COMP4651: Cloud Computing and Big Data Systems (Spring/Fall 2021, Spring 2024) \\
& $\diamond$ COMP3511: Operating Systems (Fall 2023) \\
& \\

% --- Section: Other experience --- %
{\textsc{Other}}
& \textbf{ACM-ICPC Competition Group} \hfill SCUT \\
{\textsc{Experience}}
& \textit{Group Member \& Team Leader} \hfill 2016 -- 2019 \\
& $\diamond$ Coach: Prof. Chuhua Xian \\
& $\diamond$ Major domains: Dynamic Programming, Number Theory, Data Structure, etc. \\

& \textbf{Machine Learning \& Cybernetics Research Group} \hfill SCUT \\
& \textit{Undergraduate Research Assistant} \hfill 2017 -- 2019 \\
& $\diamond$ Advisor: Prof. Patrick Chan \\
& $\diamond$ Projects: Fundus Stitching, Tableware Recognition, and NN Visualization. \\

& \textbf{Tencent Innovation Club} \hfill SCUT, CSE \\
& \textit{Vice Chairman} \hfill 2018 -- 2019 \\
& $\diamond$ Led the \textit{largest} student club in SCUT CSE, sponsored by Tencent. \\

& \textbf{ByteDance Summer Camp} \hfill Beijing, China \\
& \textit{Camper}, Algorithm track \hfill Aug. 2019 \\
& $\diamond$ Mentor: Dr. Yibo Zhu \\
& $\diamond$ Totally 150 participants selected from more than 6k candidates. \\
% & $\diamond$ Trained a large scale BERT Model by using Pipeline and Model Parallelism. \\

% International Conference on Machine Learning and Cybernetics, International Conference on Wavelet Analysis and Pattern Recognition
% & \textbf{ICMLC \& ICWAPR} \hfill Chengdu, China \\
% & \textit{Student helper} \hfill Jul. 2018 \\

& \\

% --- Section: Various skills (programming, software, languages, etc.) ---
\nohyphens{\textsc{Skills}}
& Programming Languages: Golang, C++, Python, Javascript \\
& Toolkits: Kubernetes, Docker, Grafana, Git, \LaTeX, SQL, MarkDown \\
& Languages: English (fluent), Mandarin (Native speaker), Cantonese (Intermediate) \\
& \\

% --- Section: Other interests/hobbies ---

% \nohyphens{\textsc{Miscellaneous}}
\nohyphens{\textsc{Misc}}
& Play basketball \& badminton \& squash, workout at the gym, foodie. \\
& My paper reading notes are available at \href{https://paper.lingyunyang.com/}{https://paper.lingyunyang.com/}. \\
% & Read various kinds of books, watch movies, play basketball \& badminton, workout at the gym, food lover. \\
% & In my spare time, I also write some blogs about interesting stuffs aperiodically. Here is my personal blog (in Chinese): \href{https://blog.yanglingyun.me/}{https://blog.yanglingyun.me/}. \\

% --- End of CV! --- %

\end{longtable}
\end{document}
